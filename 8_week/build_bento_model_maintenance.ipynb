{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b74b1ba",
   "metadata": {},
   "source": [
    "# Build bento model maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525761d",
   "metadata": {},
   "source": [
    "The best model obtained in the notebook, which was the XGBoost model, will be build into a bento model, thats the reason of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0349074",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcfbb5b",
   "metadata": {},
   "source": [
    "The following libraries are needed to create the bento model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a8e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import bentoml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fc1d6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07050c7",
   "metadata": {},
   "source": [
    "First lets load the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7004d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/FranciscoOrtizTena/ML_Zoomcamp/main/8_week/predictive_maintenance.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebc9f0",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0c5a0",
   "metadata": {},
   "source": [
    "Let's prepare the data as we did in the notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cabaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ','_')\n",
    "df = df.drop(['udi', 'product_id'], axis=1)\n",
    "df.failure_type = df.failure_type.str.lower().str.replace(' ','_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4935134",
   "metadata": {},
   "source": [
    "Now let's split the data into the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26c98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=2)\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train.target.values\n",
    "\n",
    "del df_full_train['target']\n",
    "del df_full_train['failure_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97650f35",
   "metadata": {},
   "source": [
    "Making the one-hot encode using DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1704ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_full_train = df_full_train.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_full_train = dv.fit_transform(dicts_full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da84c2",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529eeabe",
   "metadata": {},
   "source": [
    "Now let's train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd3bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfulltrain = xgb.DMatrix(X_full_train, label=y_full_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9859d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 10,\n",
    "    \n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    \n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dfulltrain, num_boost_round=175)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454a29e",
   "metadata": {},
   "source": [
    "## BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704b937",
   "metadata": {},
   "source": [
    "Finally let's save the model into the bentoml.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd04f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"maintenance_predict_model:asw4gns4q2vxgjv5\", path=\"/Users/Frank/bentoml/models/maintenance_predict_model/asw4gns4q2vxgjv5/\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.xgboost.save_model(\n",
    "    'maintenance_predict_model',\n",
    "    model,\n",
    "    custom_objects={\n",
    "        'dictVectorizer': dv\n",
    "    },\n",
    "    signatures={\n",
    "        'predict': {\n",
    "            'batchable': True,\n",
    "            'batch_dim': 0,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
